{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinsengi/sharpdim/blob/main/simpleFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IpP-6FE2JgtL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gradW(model, dataloader, ndata, k=1):\n",
        "    # assert dataloader.batch_size == 1\n",
        "    gradtheta = 0\n",
        "    gradW = 0\n",
        "    B = 0\n",
        "    for _ in range(ndata):\n",
        "        X, y = next(dataloader)\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "        logits = model(X).reshape(1, -1)\n",
        "        output_dim = logits.shape[1]\n",
        "        normX = torch.linalg.vector_norm(X.flatten(), 2).item()\n",
        "        old_gradW = gradW\n",
        "        for j in range(output_dim):\n",
        "            logit = logits[0][j]\n",
        "            model.zero_grad()\n",
        "            logit.backward(retain_graph=True)\n",
        "\n",
        "            grad = [p.grad.detach().cpu().numpy() for p in model.parameters()]\n",
        "            grad = [np.reshape(g, (-1)) for g in grad]\n",
        "            cur_gradtheta = np.concatenate(grad)\n",
        "            W = get_first_layer_weight(model)\n",
        "            if W is not None:\n",
        "                cur_gradW = W.grad.detach().cpu().numpy()\n",
        "            else:\n",
        "                cur_gradW = 0\n",
        "            gradtheta += np.sum(cur_gradtheta**2)\n",
        "            gradW += np.sum(cur_gradW**2)\n",
        "        B += np.sqrt(gradW - old_gradW) / normX\n",
        "    return np.sqrt(gradW / ndata), np.sqrt(gradtheta / ndata), B / ndata\n",
        "\n",
        "\n",
        "def get_first_layer_weight(model):\n",
        "    for param in model.parameters():\n",
        "        if len(param.shape) == 2:  # Check if the parameter is a weight matrix (2D)\n",
        "           return param\n",
        "        break\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_dim(model, dataloader, ndata):\n",
        "    # assert dataloader.batch_size == 1\n",
        "    dim = 0\n",
        "    log_vol = 0\n",
        "    G = 0\n",
        "    A = 0\n",
        "    B = 0\n",
        "    for _ in range(ndata):\n",
        "        X, y = next(dataloader)\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "        X.requires_grad = True\n",
        "        logits = model(X).reshape(1, -1)\n",
        "        grad_x = np.zeros((logits.shape[1], torch.numel(X)))\n",
        "        old_G = G\n",
        "        for j in range(logits.shape[1]):\n",
        "            logit = logits[0][j]\n",
        "            model.zero_grad()\n",
        "            grad = torch.autograd.grad(logit, X, retain_graph=True)[0]\n",
        "            grad = grad.cpu().detach().numpy()\n",
        "            grad = np.reshape(grad, (-1))\n",
        "            grad_x[j, :] = grad\n",
        "            G += np.sum(grad**2)\n",
        "        sing_val = np.linalg.svd(grad_x, compute_uv=False)\n",
        "        eig_val = sing_val**2\n",
        "        A += np.max(sing_val)\n",
        "        cur_dim = np.sum(eig_val) ** 2 / np.sum(eig_val**2)\n",
        "        dim += cur_dim\n",
        "        log_vol += cal_logvol(eig_val, cur_dim)\n",
        "    return dim / ndata, log_vol / ndata, G / ndata, eig_val, A / ndata\n",
        "\n",
        "\n",
        "def cal_logvol(eig_val, dim):\n",
        "    # return np.sum(np.log(eig_val[:math.floor(dim.item())])) / 2\n",
        "    return np.sum(np.log(eig_val[:3])) / 2\n",
        "\n",
        "\n",
        "def min_norm(dataloader, ndata):\n",
        "    min_norm = 1e10\n",
        "    for i in range(ndata):\n",
        "        X, y = next(dataloader)\n",
        "        min_norm = min(min_norm, torch.linalg.matrix_norm(X, \"fro\").item())\n",
        "    return min_norm\n",
        "\n",
        "\n",
        "def quad_mean(dataloader, ndata):\n",
        "    quad = 0\n",
        "    for i in range(ndata):\n",
        "        X, y = next(dataloader)\n",
        "        quad += 1 / torch.linalg.vector_norm(X.flatten(), 2).item() ** 2\n",
        "    return np.sqrt(quad / ndata)"
      ],
      "metadata": {
        "id": "0gRmKxIXKUqf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNN(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim):\n",
        "        super(FNN, self).__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(in_dim,hid_dim),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(hid_dim,hid_dim),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(hid_dim,hid_dim),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(hid_dim,out_dim))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        o = self.net(x)\n",
        "        return o"
      ],
      "metadata": {
        "id": "RRA0rB_4Jo2f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download and load the MNIST dataset\n",
        "mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "FashionMNIST_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "# Create a DataLoader\n",
        "batch_size = 32\n",
        "mnist_dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
        "fashionmnist_dataloader = DataLoader(FashionMNIST_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "yTuRVuZ4J8rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb462cca-d894-4293-f7f6-97aaa0ef44a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 99036005.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 34354989.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30750278.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 19399723.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14914250.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 264405.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4917434.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6537171.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "model = FNN(28*28, 500, 10).to(device)\n",
        "\n",
        "# Step 4: Loss Function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Step 5: Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Step 6: Training Loop\n",
        "num_epochs = 300\n",
        "G_list = []\n",
        "sharpness_list = []\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  for X_train, y_train in fashionmnist_dataloader:\n",
        "    X_train, y_train = X_train.cuda(), y_train.cuda()\n",
        "    y_train = torch.nn.functional.one_hot(y_train, 10).float().cuda()\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  # if (epoch + 1) % 1 == 0:\n",
        "  #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "      dim_dataloader = DataLoader(mnist_dataset, batch_size=1, shuffle=True)\n",
        "      dim, log_vol, G, eig_val, A = get_dim(model, iter(dim_dataloader), 20)\n",
        "      gradW, sharpness, B = get_gradW(model, iter(dim_dataloader), 20)\n",
        "\n",
        "      G_list.append(G)\n",
        "      sharpness_list.append(sharpness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "04Qid-bAKUlH",
        "outputId": "025c5198-4d94-4916-b177-51dcef7cd67d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'FNN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ceff469f717a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 4: Loss Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSMTdPy1I9PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate dimension, log volume, G and eigenvalues.\n",
        "dim_dataloader = DataLoader(mnist_dataset, batch_size=1, shuffle=True)\n",
        "dim, log_vol, G, eig_val, A = get_dim(model, iter(dim_dataloader), 20)\n"
      ],
      "metadata": {
        "id": "8AXJcDPRKUuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate sharpness\n",
        "gradW, sharpness, B = get_gradW(model, iter(dim_dataloader), 20)"
      ],
      "metadata": {
        "id": "WPD_vpaSTjjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate min input 2-norm and the norm of first layer.\n",
        "W_norm = None\n",
        "for param in model.parameters():\n",
        "    if (\n",
        "        len(param.shape) == 2\n",
        "    ):  # Check if the parameter is a weight matrix (2D)\n",
        "        W_norm = torch.linalg.matrix_norm(param, 2)\n",
        "    break\n",
        "quad = quad_mean(iter(dim_dataloader), 20)"
      ],
      "metadata": {
        "id": "Tp9AVc0zTkH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_dir(path=\"./model\"):\n",
        "    isExist = os.path.exists(path)\n",
        "    if not isExist:\n",
        "        os.makedirs(path)\n",
        "\n",
        "def save_model(model, optimizer, path, filename):\n",
        "    create_dir(path)\n",
        "    states = [model.state_dict(), optimizer.state_dict()]\n",
        "    torch.save(states, os.path.join(path, filename))\n",
        "\n",
        "save_model(model, optimizer, \"./weights\", \"test\")"
      ],
      "metadata": {
        "id": "uja9i-MVYxav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}